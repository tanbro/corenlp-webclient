import os
import unittest

from dotenv import load_dotenv

from corenlp_webclient import (CoreNlpWebClient, WordsToSentenceAnnotator,
                               create_annotator, join_chain_words,
                               join_extract_words)

load_dotenv()
URL = os.environ['CORENLP_SERVER_URL']


def make_annotator(*args, **kwargs):
    return create_annotator(WordsToSentenceAnnotator, *args, **kwargs)


class SsplitTestCase(unittest.TestCase):

    def test_one_simple_no_annotator(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹—
        '''
        result = CoreNlpWebClient(URL).api_call(text)
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_one_simple_no_options(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹—
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_one_simple_twice(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹—
        '''
        client = CoreNlpWebClient(URL)
        annotator = make_annotator()
        for _ in range(2):
            result = client.api_call(text, annotator)
            self.assertEqual(join_chain_words(result), segmented.strip())

    def test_two_with_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ã€‚ç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ã€‚
ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            make_annotator(boundary_token_regex=r'[.ã€‚]|[!?ï¼ï¼Ÿ]+')
        )
        self.assertEqual(len(result['sentences']), 2)
        self.assertEqual(join_extract_words(result), segmented.strip())

    def test_two_with_zh_boundary_twice(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ã€‚ç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ã€‚
ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        client = CoreNlpWebClient(URL)
        annotator = make_annotator(boundary_token_regex=r'[.ã€‚]|[!?ï¼ï¼Ÿ]+')
        for _ in range(2):
            result = client.api_call(text, annotator)
            self.assertEqual(len(result['sentences']), 2)
            self.assertEqual(join_extract_words(result), segmented.strip())

    def test_two_without_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ã€‚ç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ã€‚
ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            make_annotator()
        )
        self.assertEqual(len(result['sentences']), 2)
        self.assertEqual(join_extract_words(result), segmented.strip())

    def test_one_has_comma_with_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ï¼Œç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ï¼Œ ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text, make_annotator(boundary_token_regex=r'[.ã€‚]|[!?ï¼ï¼Ÿ]+'))
        self.assertEqual(join_chain_words(result), segmented.strip())
        self.assertEqual(len(result['sentences']), 1)

    def test_one_has_comma_without_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ï¼Œç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ï¼Œ ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())
        self.assertEqual(len(result['sentences']), 1)

    def test_one_simple_with_emoji(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ğŸ•
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ğŸ•
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_tow_with_emoji(self):
        text = '''
å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ğŸ•ã€‚
æˆ‘èƒ½åä¸‹ç»ç’ƒğŸ¸è€Œä¸ä¼¤èº«ä½“ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹—ğŸ• ã€‚
æˆ‘ èƒ½ åä¸‹ ç»ç’ƒ ğŸ¸ è€Œ ä¸ ä¼¤ èº«ä½“ ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_extract_words(result), segmented.strip())
        self.assertEqual(len(result['sentences']), 2)

    def test_one_with_emoji_in_head(self):
        text = '''
ğŸ•ç‹—æ˜¯äººç±»çš„å¥½æœ‹å‹
        '''
        segmented = '''
ğŸ• ç‹— æ˜¯ äººç±» çš„ å¥½ æœ‹å‹
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_one_with_continues_emojis_in_head(self):
        text = '''
ğŸ•ğŸ•ç‹—æ˜¯äººç±»çš„å¥½æœ‹å‹
        '''
        segmented = '''
ğŸ•ğŸ• ç‹— æ˜¯ äººç±» çš„ å¥½ æœ‹å‹
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_one_with_emoji_in_tail(self):
        text = '''
äººç±»çš„å¥½æœ‹å‹ä¸ä»…ä»…æ˜¯ç‹—ğŸ•
        '''
        segmented = '''
äººç±» çš„ å¥½ æœ‹å‹ ä¸ä»…ä»… æ˜¯ ç‹— ğŸ•
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_one_with_continues_emojis_in_tail(self):
        text = '''
äººç±»çš„å¥½æœ‹å‹ä¸ä»…ä»…æ˜¯ç‹—ğŸ•ğŸ•
        '''
        segmented = '''
äººç±» çš„ å¥½ æœ‹å‹ ä¸ä»…ä»… æ˜¯ ç‹—ğŸ•ğŸ•
        '''
        result = CoreNlpWebClient(URL).api_call(text, make_annotator())
        self.assertEqual(join_chain_words(result), segmented.strip())


if __name__ == '__main__':
    unittest.main()
