import os
import unittest

from dotenv import load_dotenv

from corenlp_webclient import CoreNlpWebClient, WordsToSentenceAnnotator, WordsToSentenceOptions, \
    join_chain_words, join_extract_words

load_dotenv()
URL = os.environ['CORENLP_SERVER_URL']


class SsplitTestCase(unittest.TestCase):
    def test_one_simple_no_options(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹—
        '''
        result = CoreNlpWebClient(URL).api_call(text, WordsToSentenceAnnotator())
        self.assertEqual(join_chain_words(result), segmented.strip())

    def test_two_with_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ã€‚ç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ã€‚
ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            WordsToSentenceAnnotator(WordsToSentenceOptions(boundaryTokenRegex=r'[.ã€‚]|[!?ï¼ï¼Ÿ]+'))
        )
        self.assertEqual(len(result['sentences']), 2)
        self.assertEqual(join_extract_words(result), segmented.strip())

    def test_two_without_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ã€‚ç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ã€‚
ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            WordsToSentenceAnnotator(WordsToSentenceOptions())
        )
        self.assertEqual(len(result['sentences']), 2)
        self.assertEqual(join_extract_words(result), segmented.strip())

    def test_one_has_comma_with_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ï¼Œç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ï¼Œ ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            WordsToSentenceAnnotator(WordsToSentenceOptions(boundaryTokenRegex=r'[.ã€‚]|[!?ï¼ï¼Ÿ]+'))
        )
        self.assertEqual(join_chain_words(result), segmented.strip())
        self.assertEqual(len(result['sentences']), 1)

    def test_one_has_comma_without_zh_boundary(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ç‹—ï¼Œç‹—å´æ²¡æœ‰ååº”ã€‚
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ç‹— ï¼Œ ç‹— å´ æ²¡æœ‰ ååº” ã€‚
        '''
        result = CoreNlpWebClient(URL).api_call(
            text,
            WordsToSentenceAnnotator(WordsToSentenceOptions())
        )
        self.assertEqual(join_chain_words(result), segmented.strip())
        self.assertEqual(len(result['sentences']), 1)

    def test_one_simple_with_emoji(self):
        text = '''
        å¿«é€Ÿçš„æ£•è‰²ç‹ç‹¸è·³è¿‡äº†æ‡’æƒ°çš„ğŸ•
        '''
        segmented = '''
        å¿«é€Ÿ çš„ æ£•è‰² ç‹ç‹¸ è·³è¿‡ äº† æ‡’æƒ° çš„ ğŸ•
        '''
        result = CoreNlpWebClient(URL).api_call(text, WordsToSentenceAnnotator())
        self.assertEqual(join_chain_words(result), segmented.strip())


if __name__ == '__main__':
    unittest.main()
